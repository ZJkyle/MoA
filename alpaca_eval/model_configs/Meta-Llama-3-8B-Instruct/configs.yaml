Meta-Llama-3-8B-Instruct:
  fn_completions: vllm_local_completions
  completions_kwargs:
    model_name: meta-llama/Meta-Llama-3-8B-Instruct
    batch_size: 8
    max_new_tokens: 512
    temperature: 0.7
    model_kwargs:
      dtype: bfloat16
      tensor_parallel_size: 4
      max_model_len: 4096 
  prompt_template: /app/alpaca_eval/prompts/alpaca_eval.txt

#!/bin/bash

DEFAULT_MODEL="deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
HF_CACHE_DIR="/app/models"

while [[ $# -gt 0 ]]; do
  key="$1"
  case $key in
    --model)
      MODEL_NAME="$2"
      shift
      shift
      ;;
    *)
      echo "âŒ unknown parameter: $1"
      exit 1
      ;;
  esac
done

MODEL_NAME="${MODEL_NAME:-$DEFAULT_MODEL}"
MODEL_ALIAS="DeepSeek-R1-Distill-Qwen-1.5B"  # æ‰‹å‹•æŒ‡å®š alias
MODEL_DIR="$HF_CACHE_DIR/$MODEL_ALIAS"

echo "ğŸ‘‰ model name: $MODEL_NAME"
echo "ğŸ“ model path: $MODEL_DIR"

# æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
if [ ! -d "$MODEL_DIR" ]; then
  echo "ğŸ“¥ æ¨¡å‹æœªä¸‹è¼‰ï¼Œé–‹å§‹å¾ HuggingFace ä¸‹è¼‰..."
  huggingface-cli download "$MODEL_NAME" --local-dir "$MODEL_DIR" --token "$HUGGINGFACE_TOKEN" --resume-download
else
  echo "âœ… æ¨¡å‹å·²å­˜åœ¨ï¼Œç•¥éä¸‹è¼‰"
fi

# å•Ÿå‹• vLLM ä¼ºæœå™¨
echo "ğŸš€ å•Ÿå‹• vLLM API server on port 8000"
python3 -m vllm.entrypoints.openai.api_server \
  --model "$MODEL_DIR" \
  --port 8000 \
  --served-model-name "$MODEL_ALIAS"
